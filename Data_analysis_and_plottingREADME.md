# Training Results Analysis Pipeline

This repository contains scripts to analyze training logs, calculate Critical Batch Size (CBS), and generate plots and tables for the paper.

## Overview

The analysis pipeline consists of three scripts that should be run in sequence:

1. `simple_log_plotter.py` - Extract and visualize training/validation results
2. `cbs_analysis.py` - Calculate CBS values from log files
3. `cbs_plot.py` - Generate CBS comparison plots
4. `final_loss_grid.py' - Generate grid of final loss & CBS plots

## Prerequisites

```bash
pip install pandas numpy matplotlib seaborn scipy
```

## Directory Structure

```
.
├── logs_branch_multi_adam/     # AdamW training logs
├── logs_branch_multi_muon/     # Muon training logs
├── final_grid_data/            # Organized data for final loss plots
├── simple_log_plotter.py
├── cbs_analysis.py
├── cbs_plot.py
├── final_loss_grid.py
├── plots_new/                  # Generated by simple_log_plotter.py
├── cbs_results/                # Generated by cbs_analysis.py
├── final_grid_plots/           # Generated by final_loss_grid.py
└── README.md
```
Currently, AdamW and Muon logs are saved as zip files (logs_branch_multi_adam.zip and logs_branch_multi_muon.zip). To repeat this experiment, you will need to unzip them.

## Usage

Run these scripts **in order** to reproduce all results:

### Step 1: Extract Training Results and Generate Plots

```bash
python simple_log_plotter.py
```

**Purpose:** Processes all training logs to extract loss curves and generate tables/plots used in the paper.

**Outputs:**
- `plots_new/raw_data.csv` - Raw data points from all log files
- `plots_new/interpolated_data.csv` - Data interpolated to 50 common points per run
- `plots_new/training_loss_table.csv` - Final training losses (mean ± SEM) for each checkpoint/k-value
- `plots_new/validation_loss_table.csv` - Final validation losses (mean ± SEM) for each checkpoint/k-value
- `plots_new/loss_tables.tex` - LaTeX tables ready for Overleaf (with proper $\pm$ formatting)
- `plots_new/adam_*_all_k_same_axis_train_loss.png` - Training loss plots for AdamW
- `plots_new/muon_*_all_k_same_axis_train_loss.png` - Training loss plots for Muon
- `plots_new/adam_4000M_individual_seeds_train_loss.png` - Individual seed plots for AdamW at 4000M

**Key Functions:**
- `parse_log_file(filepath)` - Extracts training/validation loss time series from a single log file
- `load_all_logs(log_dirs)` - Loads all logs from AdamW and Muon directories, filters by valid k-values
- `interpolate_to_common_points(df, n_points=50)` - Interpolates all runs to 50 evenly-spaced token positions for consistent aggregation
- `plot_all_k_on_same_axis(df, optimizer, checkpoint, metric_name, output_dir)` - Creates plots showing all k-values on same axis with mean ± SEM
- `plot_all_k_single_seeds(df, optimizer, checkpoint, metric_name, output_dir)` - Creates 3-panel plots showing individual seed results
- `generate_validation_table(df, ...)` - Aggregates final validation losses across seeds
- `generate_training_loss_table(df, ...)` - Aggregates final training losses across seeds
- `generate_latex_tables(train_table, val_table, output_dir)` - Converts CSV tables to LaTeX format with proper math symbols

**Configuration:**
- `VALID_K_VALUES = [0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 1024]` - Only these k-values are included
- `N_INTERPOLATION_POINTS = 50` - Number of points for interpolation
- Font sizes and plot styling can be adjusted in the configuration section

---

### Step 2: Calculate Critical Batch Size (CBS)

```bash
python cbs_analysis.py
```

**Purpose:** Extracts final training/validation losses from log files and calculates CBS for each checkpoint. Creates CSV files needed for the final CBS plot.

**Outputs:**
- `cbs_results/cbs_data_adam.csv` - AdamW results: Checkpoint, K-value, Seed, Train Loss, Val Loss, Log File
- `cbs_results/cbs_data_muon.csv` - Muon results: Checkpoint, K-value, Seed, Train Loss, Val Loss, Log File

**Key Functions:**
- `extract_info_from_log(log_file)` - Parses a single log file to extract checkpoint, k-value, seed, final training loss, and final validation loss
  - First tries to parse from filename pattern: `branch_{checkpoint}_k{k}_seed{seed}_{timestamp}.log`
  - Falls back to parsing file content if filename parsing fails
  - Only includes k-values in `VALID_K_VALUES` list
- `collect_results_from_logs(log_directory)` - Recursively finds all `.log` and `.txt` files in a directory and extracts info from each
  - Returns a dictionary mapping checkpoint → list of results
  - Filters and reports statistics on successful/failed/filtered files
- `main()` - Orchestrates the extraction process for both AdamW and Muon optimizers
  - Processes `logs_branch_multi_adam/` and `logs_branch_multi_muon/`
  - Saves results to CSV files in `cbs_results/` directory

**Configuration:**
- `VALID_K_VALUES = [0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 1024]` - Must match `simple_log_plotter.py`
- `LOG_DIRS` - Specifies directories containing AdamW and Muon logs

**Notes:**
- This script has been cleaned to remove unused CBS calculation and LaTeX table generation functions
- Only extracts data and saves to CSV; CBS calculation happens in Step 3

---

### Step 3: Generate CBS Comparison Plot

```bash
python cbs_plot.py
```

**Purpose:** Calculates CBS from the CSV files generated in Step 2 and creates the main CBS comparison plot used in the paper.

**Outputs:**
- `effective_cbs_plot.pdf` - Main figure showing CBS vs. training progress for AdamW and Muon
- Console output with detailed CBS statistics by checkpoint, seed, and optimizer

**Key Functions:**
- `calculate_cbs(df, checkpoint, epsilon=0.5)` - Calculates CBS for a checkpoint by:
  - Grouping by k-value and calculating mean validation loss across seeds
  - Finding minimum loss
  - Finding largest k where loss ≤ min_loss + epsilon
- `get_cbs_by_seed(df, checkpoint, epsilon=0.5)` - Calculates CBS separately for each individual seed
  - Used to compute mean and standard error across seeds
- Main plotting code:
  - Calculates CBS for each checkpoint in both AdamW and Muon
  - Computes mean CBS and 95% confidence intervals across 3 seeds
  - Generates error bar plot with log-scale y-axis
  - AdamW shown in dark blue (#0B3C78), Muon in light blue (#4FA3FF)

**Configuration:**
- `epsilon = 0.5` - Tolerance threshold for CBS calculation (loss can be at most 0.5 higher than minimum)
- `checkpoints = ['50M', '500M', '1000M', '1500M', '2000M', '3000M', '4000M']` - Training checkpoints
- `tokens = [50e6, 500e6, 1e9, 1.5e9, 2e9, 3e9, 4e9]` - Corresponding token counts

**Console Output:**
The script prints a detailed table showing:
- CBS for each seed (0, 1, 2) at each checkpoint
- Mean CBS and standard error for each checkpoint/optimizer combination
- Summary statistics

---

### Step 4: Generate Final Loss with CBS Plots

```bash
python final_loss_grid.py
```

**Purpose:** Creates grid of final train/validation loss plots with identified CBS for various epsilon values.

**Outputs:**
- Plots in folder final_grid_plots

**Key Functions:**
- Main plotting code:
  - Generates Plots for Figure 1 and Figures 9-12 in the Appendix using the data
  - Data has been pre-moved from the logs to organized JSON files for these plots

## Complete Workflow Example

```bash
# Step 1: Generate all plots and tables
python simple_log_plotter.py
# → Creates plots_new/ directory with plots and tables

# Step 2: Extract CBS data from logs
python cbs_analysis.py
# → Creates cbs_results/ directory with CSV files

# Step 3: Plot CBS comparison
python cbs_plot.py
# → Creates effective_cbs_plot.pdf
```

---

## File Formats

### Log File Format
Expected log file naming: `branch_{checkpoint}_k{k_value}_seed{seed}_{timestamp}.log`

Example: `branch_4000M_k8_seed0_20251127.log`

Log files should contain lines like:
```
tokens: 507,904 | loss: 4.0437 | grad_norm: 0.9287
...
Validation loss: 4.1234
...
Final validation loss: 4.0123
```

### CSV Output Format

**training_loss_table.csv / validation_loss_table.csv:**
```csv
Optimizer,Checkpoint,K,Final Val Loss (Mean),SEM,Mean ± SEM,Min (any point),Max (any point),N Seeds
ADAM,4000M,8,4.1234,0.0123,4.1234 ± 0.0123,4.0500,4.2000,3
```

**cbs_data_adam.csv / cbs_data_muon.csv:**
```csv
Checkpoint,K-value,Seed,Train Loss,Val Loss,Log File
4000M,8,0,4.1234,4.1567,logs_branch_multi_adam/branch_4000M_k8_seed0_20251127.log
```

---

## Troubleshooting

**Issue:** "No log files found"
- Check that log directories (`logs_branch_multi_adam/`, `logs_branch_multi_muon/`) exist
- Verify log files match the expected naming pattern

**Issue:** "No data extracted from logs"
- Check log file format contains required patterns (tokens, loss, grad_norm)
- Verify k-values in filenames are in `VALID_K_VALUES` list

**Issue:** Missing plots or tables
- Ensure all three scripts complete successfully without errors
- Check output directories (`plots_new/`, `cbs_results/`) are created
- Verify sufficient data exists for each checkpoint/k-value/seed combination

---

## Configuration Notes

### Valid K-Values
Both `simple_log_plotter.py` and `cbs_analysis.py` use:
```python
VALID_K_VALUES = [0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 1024]
```

Only experiments with these k-values are included in the analysis. Logs with other k-values are filtered out.

### Aggregation Method
- Training/validation tables use the **last 10% of training** to compute final loss
- CBS calculation uses **final validation loss** (last reported value)
- All aggregations compute **mean ± SEM** across 3 seeds

### Color Scheme
Colors are consistent across all plots:
- Each k-value gets a unique color from the "husl" palette
- Same k-value always uses the same color across different plots
- AdamW vs Muon use different colors in CBS plot (#0B3C78 vs #4FA3FF)

---

## Output Files Summary

| File | Created By | Purpose |
|------|------------|---------|
| `plots_new/raw_data.csv` | simple_log_plotter.py | All extracted data points |
| `plots_new/interpolated_data.csv` | simple_log_plotter.py | Data after interpolation |
| `plots_new/training_loss_table.csv` | simple_log_plotter.py | Final training losses |
| `plots_new/validation_loss_table.csv` | simple_log_plotter.py | Final validation losses |
| `plots_new/loss_tables.tex` | simple_log_plotter.py | LaTeX tables for Overleaf |
| `plots_new/*.png` | simple_log_plotter.py | All training loss plots |
| `cbs_results/cbs_data_adam.csv` | cbs_analysis.py | AdamW CBS data |
| `cbs_results/cbs_data_muon.csv` | cbs_analysis.py | Muon CBS data |
| `effective_cbs_plot.pdf` | cbs_plot.py | Main CBS comparison figure |
