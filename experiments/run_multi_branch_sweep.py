"""
Run branched training experiments across multiple checkpoints and seeds.

This script runs all the configs generated by generate_multi_checkpoint_configs.py,
which includes multiple checkpoints with multiple seeds per checkpoint.

Features:
- Runs branches sequentially (one at a time)
- Saves logs for each run
- Supports resume functionality
- Provides progress tracking and summaries
"""

import os
import sys
import time
import subprocess
from datetime import datetime
from pathlib import Path

# =============================================================================
# CONFIGURATION - Should match generate_multi_checkpoint_configs.py
# =============================================================================

CONFIG_DIR = "configs_branch_multi"
LOGS_DIR = "logs_branch_multi"
TRAIN_SCRIPT = "/home/ejweaver/cbs/train.py"  # Run from parent dir where this file is located

# These should match your config generation script
CHECKPOINTS = [
    ("/data/ejweaver/out_cbs/adamw_full_5B_run_fixed", "checkpoint_500M.pt", "500M"),
    ("/data/ejweaver/out_cbs/adamw_full_5B_run_fixed", "checkpoint_2500M.pt", "1000M"),
    ("/data/ejweaver/out_cbs/adamw_full_5B_run_fixed", "checkpoint_3500M.pt", "1500M"),
    ("/data/ejweaver/out_cbs/adamw_full_5B_run_fixed", "checkpoint_4500M.pt", "2000M"),
]
BRANCH_SEEDS = [0, 1, 2]
K_VALUES = [1, 2, 4, 8, 16, 32]

# =============================================================================
# END OF CONFIGURATION
# =============================================================================


def get_config_filename(checkpoint_file: str, k: int, seed: int) -> str:
    """
    Generate the config filename for a checkpoint-k-seed combination.
    
    Args:
        checkpoint_file: Checkpoint filename (e.g., "ckpt.pt")
        k: K-value
        seed: Random seed
    
    Returns:
        Config filename
    """
    ckpt_name = checkpoint_file.replace('.pt', '')
    return f"config_{ckpt_name}_k{k}_seed{seed}.py"


def collect_config_files():
    """
    Collect all config files organized by checkpoint and seed.
    
    Returns:
        List of tuples: (checkpoint_step, k, seed, config_path)
    """
    if not os.path.exists(CONFIG_DIR):
        return []
    
    config_files = []
    
    for checkpoint_dir, checkpoint_file, checkpoint_step in CHECKPOINTS:
        for seed in BRANCH_SEEDS:
            for k in K_VALUES:
                config_filename = get_config_filename(checkpoint_file, k, seed)
                config_path = os.path.join(CONFIG_DIR, config_filename)
                
                if os.path.exists(config_path):
                    config_files.append((checkpoint_step, k, seed, config_path))
                else:
                    print(f"Warning: Config file not found: {config_path}")
    
    return config_files


def run_single_branch(checkpoint_step: str, k: int, seed: int, config_path: str, log_path: str) -> dict:
    """
    Run a single branched training experiment.
    
    Args:
        checkpoint_step: Checkpoint identifier (e.g., "100k")
        k: K-value
        seed: Random seed
        config_path: Path to config file
        log_path: Path to save log file
    
    Returns:
        Dictionary with run metadata
    """
    start_time = time.time()
    
    print(f"\n{'='*70}")
    print(f"Running Branch: Checkpoint={checkpoint_step}, k={k}, seed={seed}")
    print(f"{'='*70}")
    print(f"Config: {config_path}")
    print(f"Log: {log_path}")
    print(f"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # Run training
    # Need to run from parent directory where configurator.py is located
    parent_dir = os.path.abspath('..')
    config_abs_path = os.path.abspath(config_path)
    log_abs_path = os.path.abspath(log_path)
    cmd = [sys.executable, TRAIN_SCRIPT, config_abs_path]
    
    with open(log_abs_path, 'w') as log_file:
        # Write header to log
        log_file.write(f"{'='*70}\n")
        log_file.write(f"Branch Training Log\n")
        log_file.write(f"{'='*70}\n")
        log_file.write(f"Checkpoint: {checkpoint_step}\n")
        log_file.write(f"K-value: {k}\n")
        log_file.write(f"Seed: {seed}\n")
        log_file.write(f"Config: {config_path}\n")
        log_file.write(f"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        log_file.write(f"{'='*70}\n\n")
        log_file.flush()
        
        # Run training and capture output
        # Run from parent directory where configurator.py is located
        try:
            result = subprocess.run(
                cmd,
                stdout=log_file,
                stderr=subprocess.STDOUT,
                text=True,
                cwd=parent_dir
            )
            success = result.returncode == 0
        except Exception as e:
            log_file.write(f"\n\nError running training: {e}\n")
            success = False
    
    end_time = time.time()
    duration = end_time - start_time
    
    # Append summary to log
    with open(log_abs_path, 'a') as log_file:
        log_file.write(f"\n\n{'='*70}\n")
        log_file.write(f"Completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        log_file.write(f"Duration: {duration:.1f}s ({duration/60:.1f}m)\n")
        log_file.write(f"Status: {'SUCCESS' if success else 'FAILED'}\n")
        log_file.write(f"{'='*70}\n")
    
    # Print completion message
    print()
    print(f"Completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"Duration: {duration:.1f}s ({duration/60:.1f}m)")
    print(f"Status: {'✓ SUCCESS' if success else '✗ FAILED'}")
    
    return {
        'checkpoint_step': checkpoint_step,
        'k': k,
        'seed': seed,
        'config': config_path,
        'log': log_path,
        'duration': duration,
        'success': success
    }


def print_results_summary(results: list):
    """
    Print a summary of all run results.
    
    Args:
        results: List of result dictionaries from run_single_branch
    """
    print()
    print("="*70)
    print("Results Summary")
    print("="*70)
    print()
    
    # Group by checkpoint
    checkpoints = {}
    for r in results:
        ckpt = r['checkpoint_step']
        if ckpt not in checkpoints:
            checkpoints[ckpt] = []
        checkpoints[ckpt].append(r)
    
    # Print results grouped by checkpoint
    for checkpoint_step in sorted(checkpoints.keys()):
        ckpt_results = checkpoints[checkpoint_step]
        success_count = sum(1 for r in ckpt_results if r['success'])
        total_count = len(ckpt_results)
        total_time = sum(r['duration'] for r in ckpt_results)
        
        print(f"Checkpoint: {checkpoint_step}")
        print(f"  Status: {success_count}/{total_count} succeeded")
        print(f"  Total time: {total_time:.1f}s ({total_time/60:.1f}m)")
        print()
        
        # Group by seed within checkpoint
        seeds = {}
        for r in ckpt_results:
            seed = r['seed']
            if seed not in seeds:
                seeds[seed] = []
            seeds[seed].append(r)
        
        for seed in sorted(seeds.keys()):
            seed_results = seeds[seed]
            print(f"  Seed {seed}:")
            for r in sorted(seed_results, key=lambda x: x['k']):
                status = "✓" if r['success'] else "✗"
                print(f"    k={r['k']:2d}: {status} ({r['duration']:6.1f}s)")
        print()
    
    # Overall summary
    total_runs = len(results)
    total_success = sum(1 for r in results if r['success'])
    total_failed = total_runs - total_success
    total_duration = sum(r['duration'] for r in results)
    
    print("="*70)
    print("Overall Summary:")
    print(f"  Total runs: {total_runs}")
    print(f"  Succeeded: {total_success}")
    print(f"  Failed: {total_failed}")
    print(f"  Total time: {total_duration:.1f}s ({total_duration/60:.1f}m, {total_duration/3600:.1f}h)")
    print(f"  Average time per run: {total_duration/total_runs:.1f}s")
    print("="*70)


def main():
    """Run the complete multi-checkpoint, multi-seed branched training sweep."""
    
    print("="*70)
    print("Multi-Checkpoint Multi-Seed Branched Training Sweep Runner")
    print("="*70)
    print()
    
    # Check if train_sweep.py exists
    if not os.path.exists(TRAIN_SCRIPT):
        print(f"Error: Training script not found: {TRAIN_SCRIPT}")
        print("Please ensure train_sweep.py is in the correct location.")
        return
    
    # Check if config directory exists
    if not os.path.exists(CONFIG_DIR):
        print(f"Error: Config directory not found: {CONFIG_DIR}")
        print("Please run generate_multi_checkpoint_configs.py first.")
        return
    
    # Create logs directory
    os.makedirs(LOGS_DIR, exist_ok=True)
    print(f"Logs will be saved to: {LOGS_DIR}/")
    print()
    
    # Collect all config files
    config_files = collect_config_files()
    
    if not config_files:
        print("Error: No config files found!")
        print(f"Expected configs in: {CONFIG_DIR}/")
        return
    
    # Display summary
    total_configs = len(config_files)
    checkpoints_found = len(set(cf[0] for cf in config_files))
    seeds_found = len(set(cf[2] for cf in config_files))
    k_values_found = len(set(cf[1] for cf in config_files))
    
    print(f"Found {total_configs} config files:")
    print(f"  • {checkpoints_found} checkpoints")
    print(f"  • {seeds_found} seeds per checkpoint")
    print(f"  • {k_values_found} k-values per seed")
    print()
    
    # Group and display by checkpoint
    checkpoints_dict = {}
    for checkpoint_step, k, seed, config_path in config_files:
        if checkpoint_step not in checkpoints_dict:
            checkpoints_dict[checkpoint_step] = []
        checkpoints_dict[checkpoint_step].append((k, seed))
    
    for checkpoint_step in sorted(checkpoints_dict.keys()):
        runs = checkpoints_dict[checkpoint_step]
        print(f"  Checkpoint {checkpoint_step}: {len(runs)} runs")
    print()
    
    # Confirm before starting
    print("This will run all branches sequentially.")
    print(f"Estimated time: Variable (depends on training)")
    print()
    response = input("Start training sweep? [y/N]: ")
    if response.lower() != 'y':
        print("Sweep cancelled.")
        return
    
    print()
    sweep_start_time = time.time()
    
    # Run each branch sequentially
    results = []
    for i, (checkpoint_step, k, seed, config_path) in enumerate(config_files, 1):
        print(f"\n{'='*70}")
        print(f"Progress: {i}/{total_configs}")
        print(f"{'='*70}")
        
        # Generate log filename
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        log_filename = f"branch_{checkpoint_step}_k{k}_seed{seed}_{timestamp}.log"
        log_path = os.path.join(LOGS_DIR, log_filename)
        
        # Run the branch
        result = run_single_branch(checkpoint_step, k, seed, config_path, log_path)
        results.append(result)
        
        # Brief pause between runs (except for the last one)
        if i < total_configs:
            print("\nWaiting 5 seconds before next branch...")
            time.sleep(5)
    
    sweep_end_time = time.time()
    sweep_duration = sweep_end_time - sweep_start_time
    
    # Display final results
    print_results_summary(results)
    
    print()
    print(f"Total sweep duration: {sweep_duration:.1f}s ({sweep_duration/60:.1f}m, {sweep_duration/3600:.1f}h)")
    print()
    print("All branches complete!")
    print()
    print("Next steps:")
    print(f"  1. Review logs in: {LOGS_DIR}/")
    print(f"  2. Check training outputs in: out_branch_*/ directories")
    print(f"  3. Analyze results on WandB (if enabled)")
    print()


if __name__ == "__main__":
    main()

